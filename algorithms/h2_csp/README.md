# H¬≤-CSP (Hybrid Hierarchical Search)
> Anteriormente denominado H¬≥-CSP (Hybrid Hierarchical Hamming Search). Renomeado para refletir foco em hierarquia + hibridiza√ß√£o (H¬≤).  
> Refactored: implementa√ß√£o unificada permanece em `algorithm.py` retornando `AlgorithmResult` conforme interface `CSPAlgorithm`.

The **H¬≤-CSP (Hybrid Hierarchical Search)** algorithm is a **three‚Äëlayer adaptive approach** for the Closest String Problem that combines **hierarchical block decomposition**, **difficulty‚Äëaware per‚Äëblock search techniques**, and **global hill‚Äëclimbing refinement**. It targets medium‚Äësized instances where structural locality can be exploited for quality vs. efficiency balance.

## üìã Index

- [Algorithm Strategy](#algorithm-strategy)
- [Three-Layer Architecture](#three-layer-architecture)
- [Detailed Operation](#detailed-operation)
- [Parameters](#parameters)
- [Use Cases](#use-cases)
- [Complexity Analysis](#complexity-analysis)
- [Examples](#examples)
- [Limitations](#limitations)
- [Integration](#integration)

## üéØ Algorithm Strategy

### Adaptive Divide‚Äëand‚ÄëConquer Philosophy
Complex CSP instances are decomposed into smaller contiguous blocks whose local difficulty guides selection of the most cost‚Äëeffective search technique per block.

### Key Advantages
- **Adaptive**: Technique automatically chosen per difficulty level
- **Hierarchical**: ‚àöL heuristic for near‚Äëbalanced contiguous block sizes
- **Hybrid**: Exhaustive search, beam search, and hill‚Äëclimbing
- **Scalable**: Controls combinatorial growth via decomposition
- **Deterministic**: Seeded execution (no stochastic divergence)

### Core Innovation: Smart-Core
Central adaptive layer measuring block difficulty (consensus max distance) and selecting:

- **Easy Blocks** ‚Üí Exhaustive search (optimal locally)
- **Medium Blocks** ‚Üí Reduced beam (beam_width/2)
- **Hard Blocks** ‚Üí Full beam search

## üèóÔ∏è Three-Layer Architecture

### Layer 1: Block Splitter
```
Entrada: String de comprimento L
‚îú‚îÄ‚îÄ Divis√£o em B ‚âà ‚åà‚àöL‚åâ blocos cont√≠guos
‚îú‚îÄ‚îÄ Tamanho de bloco ‚âà L/B
‚îî‚îÄ‚îÄ Sa√≠da: Lista de blocos [(0,b‚ÇÅ), (b‚ÇÅ,b‚ÇÇ), ..., (b‚Çô‚Çã‚ÇÅ,L)]
```

**Example**: L=16 ‚Üí B=4 blocks ‚Üí [(0,4), (4,8), (8,12), (12,16)]

### Layer 2: Smart-Core (Adaptive Block Processing)
```
Para cada bloco:
‚îú‚îÄ‚îÄ Calcula consenso local
‚îú‚îÄ‚îÄ Mede dificuldade d_b = max_distance(consenso, bloco_strings)
‚îú‚îÄ‚îÄ Seleciona t√©cnica baseada em d_b:
‚îÇ   ‚îú‚îÄ‚îÄ d_b ‚â§ 2: Busca Exaustiva
‚îÇ   ‚îú‚îÄ‚îÄ 2 < d_b ‚â§ 4: Beam Search (largura/2)
‚îÇ   ‚îî‚îÄ‚îÄ d_b > 4: Beam Search (largura completa)
‚îî‚îÄ‚îÄ Gera k candidatos para o bloco
```

### Layer 3: Global Refine (Fusion + Local Search)
```
‚îú‚îÄ‚îÄ Fus√£o: Concatena melhores candidatos de cada bloco
‚îú‚îÄ‚îÄ Hill-Climbing: Refinamento posi√ß√£o-a-posi√ß√£o
‚îî‚îÄ‚îÄ Itera√ß√£o at√© converg√™ncia ou limite de tempo
```

## ‚öôÔ∏è Detailed Operation

### Phase 1: Hierarchical Decomposition (B-Splitter)
```python
def split_in_blocks(L: int) -> list[Block]:
    B = ceil(‚àöL)  # N√∫mero de blocos
    block_size = ceil(L / B)  # Tamanho base
    # Distribui posi√ß√µes uniformemente
```

**Rationale**: ‚àöL balances granularity (too many small blocks) vs. overhead (too few large blocks).

### Phase 2: Adaptive Processing (Smart-Core)

#### Difficulty Measurement
```python
consensus = majority_vote(strings_block)
d_b = max_hamming_distance(consensus, strings_block)
```

#### Technique Selection
```python
if d_b <= block_small:          # Padr√£o: 2
    # Busca Exaustiva
    candidates = all_strings_of_length_m(alphabet, block_length)
    return best_k_candidates(candidates)
    
elif d_b <= block_medium:       # Padr√£o: 4
    # Beam Search Reduzido
    return beam_search(beam_width // 2)
    
else:                           # d_b > 4
    # Beam Search Completo
    return beam_search(beam_width)
```

#### Exhaustive Search (Easy Blocks)
```python
# Para bloco de tamanho m, testa todos |Œ£|^m candidatos
for candidate in product(alphabet, repeat=m):
    distance = max_hamming(candidate, block_strings)
    # Mant√©m k melhores
```

#### Beam Search (Medium / Hard Blocks)
```python
beam = [""]  # Prefixo vazio
for position in range(block_length):
    new_beam = []
    for prefix in beam:
        for char in alphabet:
            new_prefix = prefix + char
            score = evaluate_partial(new_prefix)
            new_beam.append((score, new_prefix))
    beam = select_best(new_beam, beam_width)
```

### Phase 3: Fusion & Global Refinement

#### Block Fusion
```python
# Concatena o melhor candidato de cada bloco
center = "".join(best_candidates_per_block)
```

#### Hill-Climbing Refinement
```python
improved = True
while improved:
    improved = False
    for position in range(len(center)):
        for new_char in alphabet_at_position[position]:
            if try_substitution_improves(position, new_char):
                center[position] = new_char
                improved = True
                break
```

## üîß Parameters

### Block Division Parameters

| Parameter | Type | Default | Description |
|-----------|------|--------|-----------|
| `auto_blocks` | bool | True | Usa divis√£o autom√°tica por ‚àöL |
| `min_block_size` | int | 2 | Tamanho m√≠nimo de bloco |
| `max_blocks` | int | None | M√°ximo de blocos (None = autom√°tico) |

### Difficulty Thresholds

| Parameter | Type | Default | Description |
|-----------|------|--------|-----------|
| `block_small` | int | 2 | Limite para busca exaustiva |
| `block_medium` | int | 4 | Limite para beam search reduzido |
| `block_large` | int | 8 | Limite para beam search completo |

### Search Parameters

| Parameter | Type | Default | Description |
|-----------|------|--------|-----------|
| `beam_width` | int | 32 | Largura do beam search |
| `k_candidates` | int | 5 | N√∫mero de candidatos por bloco |
| `exhaustive_limit` | int | 10000 | Limite para busca exaustiva |

### Refinement Parameters

| Parameter | Type | Default | Description |
|-----------|------|--------|-----------|
| `local_iters` | int | 3 | Itera√ß√µes de hill-climbing |
| `max_time` | int | 300 | Timeout em segundos |
| `seed` | int | None | Semente para reprodutibilidade |

## üìä Use Cases

### üü¢ Ideal For
- **Inst√¢ncias M√©dias**: L=50-500, n=10-100 strings
- **Dados com Estrutura Local**: Padr√µes regionais preservados
- **Busca de Alta Qualidade**: Quando precis√£o √© importante
- **An√°lise Comparativa**: Benchmark contra outros algoritmos

### üü° Suitable For
- **Datasets Balanceados**: Nenhuma regi√£o extremamente dif√≠cil
- **Problemas Estruturados**: Sequ√™ncias biol√≥gicas, texto com padr√µes
- **Experimenta√ß√£o**: Ajuste fino de par√¢metros
- **Desenvolvimento**: Prototipagem de novas t√©cnicas

### üî¥ Less Suitable For
- **Inst√¢ncias Muito Pequenas**: Overhead de divis√£o √© desnecess√°rio
- **Inst√¢ncias Muito Grandes**: L>1000 pode ser lento
- **Tempo Real**: M√∫ltiplas fases podem introduzir lat√™ncia
- **Dados Completamente Aleat√≥rios**: Estrutura local √© inexistente

## üìà Complexity Analysis

### Complexidade por Fase

#### Fase 1: B-Splitter
- **Tempo**: O(L) - divis√£o linear
- **Espa√ßo**: O(B) - lista de blocos

#### Fase 2: Smart-Core
- **Busca Exaustiva**: O(|Œ£|^m √ó k) por bloco pequeno
- **Beam Search**: O(m √ó |Œ£| √ó beam_width) por bloco grande
- **Total**: O(B √ó max(|Œ£|^m_avg, m_avg √ó |Œ£| √ó beam_width))

#### Fase 3: Global Refine
- **Fus√£o**: O(B) - concatena√ß√£o
- **Hill-Climbing**: O(local_iters √ó L √ó |Œ£|)

### Complexidade Total
```
Melhor caso: O(L + B √ó |Œ£| √ó beam_width + local_iters √ó L √ó |Œ£|)
Pior caso: O(L + B √ó |Œ£|^(L/B) + local_iters √ó L √ó |Œ£|)
Caso t√≠pico: O(L √ó |Œ£| √ó beam_width)
```

### Performance Estimada
```
L=50,  n=20:   1-5 segundos
L=100, n=50:   5-15 segundos
L=200, n=100:  15-60 segundos
L=500, n=200:  1-5 minutos
```

### Scaling com ‚àöL
O brilhantismo do H¬≤-CSP est√° na regra ‚àöL:
- **L=16**: 4 blocos de tamanho 4
- **L=64**: 8 blocos de tamanho 8  
- **L=256**: 16 blocos de tamanho 16
- **L=1024**: 32 blocos de tamanho 32

## üí° Exemplos de Uso

### Exemplo 1: Configura√ß√£o B√°sica
```python
from algorithms.h2_csp import H2CSPAlgorithm

strings = ["ACGTACGT", "AGCTACGT", "ATGTACGT", "ACATACGT"]
algorithm = H2CSPAlgorithm(strings, alphabet="ACGT")
center, distance, metadata = algorithm.run()

print(f"Centro H¬≤-CSP: {center}")
print(f"Dist√¢ncia: {distance}")
print(f"Blocos processados: {len(algorithm.h2_csp_instance.blocks)}")
```

### Exemplo 2: Ajuste Fino de Par√¢metros
```python
algorithm = H2CSPAlgorithm(
    strings,
    alphabet="ACGT",
    beam_width=64,
    k_candidates=8,
    local_iters=5,
    block_small=1,
    block_medium=3
)
center, distance, metadata = algorithm.run()
```

### Exemplo 3: Monitoramento de Progresso
```python
def progress_handler(message):
    print(f"[H¬≤-CSP] {message}")

algorithm = H2CSPAlgorithm(strings, "ACGT")
algorithm.set_progress_callback(progress_handler)
center, distance, metadata = algorithm.run()
```

### Exemplo 4: An√°lise de Performance
```python
def benchmark_h2_csp(strings_list, label):
    print(f"\n=== {label} ===")
    algorithm = H2CSPAlgorithm(strings_list, "ACGT", max_time=60)
    
    start = time.time()
    center, distance, metadata = algorithm.run()
    elapsed = time.time() - start
    
    print(f"Strings: {len(strings_list)}, Comprimento: {len(strings_list[0])}")
    print(f"Blocos: {len(algorithm.h2_csp_instance.blocks)}")
    print(f"Resultado: d={distance} em {elapsed:.2f}s")
    print(f"Par√¢metros: {metadata['parametros_usados']}")
```

### Exemplo 5: Compara√ß√£o Multi-Algoritmo
```python
from algorithms.baseline import BaselineAlgorithm
from algorithms.csc import CSCAlgorithm
from algorithms.h2_csp import H2CSPAlgorithm

def compare_algorithms(strings):
    algorithms = [
        ("Baseline", BaselineAlgorithm),
        ("CSC", CSCAlgorithm),
        ("H¬≤-CSP", H2CSPAlgorithm)
    ]
    
    results = {}
    for name, AlgClass in algorithms:
        start = time.time()
        center, distance, _ = AlgClass(strings, "ACGT").run()
        elapsed = time.time() - start
        results[name] = {"distance": distance, "time": elapsed}
    
    print("=== Compara√ß√£o de Algoritmos ===")
    for name, result in results.items():
        print(f"{name:10}: d={result['distance']} em {result['time']:.2f}s")

# Executar compara√ß√£o
test_strings = ["ACGTACGT", "AGCTACGT", "ATGTACGT", "AAGTACGT"]
compare_algorithms(test_strings)
```

## ‚ö†Ô∏è Limita√ß√µes

### Limita√ß√µes T√©cnicas
1. **Overhead de Divis√£o**: Para inst√¢ncias muito pequenas (L<10), a divis√£o pode ser contraproducente
2. **Depend√™ncia de Estrutura**: Performance degrada com dados completamente aleat√≥rios
3. **Mem√≥ria para Candidatos**: k_candidates √ó B pode consumir mem√≥ria significativa
4. **Determinismo vs Qualidade**: Pode ficar preso em √≥timos locais durante hill-climbing

### Limita√ß√µes Pr√°ticas
1. **Configura√ß√£o de Par√¢metros**: Muitos par√¢metros para ajustar
2. **Compreens√£o Complexa**: Algoritmo mais dif√≠cil de entender que baselines
3. **Debug Complexo**: Tr√™s fases dificultam identifica√ß√£o de problemas
4. **Sensibilidade a Limiares**: block_small e block_medium afetam drasticamente performance

### Cen√°rios Problem√°ticos
```python
# Caso 1: Strings muito curtas (overhead desnecess√°rio)
strings = ["AC", "AT", "AG", "AA"]  # L=2, apenas 1-2 blocos

# Caso 2: Strings completamente aleat√≥rias
strings = ["AAAA", "TTTT", "GGGG", "CCCC"]  # Sem estrutura local

# Caso 3: Um bloco dominante
strings = ["A"*50 + "TTTTT", "A"*50 + "GGGGG"]  # 1¬∫ bloco trivial, 2¬∫ dif√≠cil

# Caso 4: Limiares mal configurados
# block_small=0 ‚Üí tudo usa beam search (perde precis√£o)
# block_small=10 ‚Üí tudo usa busca exaustiva (muito lento)
```

### Troubleshooting
```python
# Problema: Muito lento
solution = "Reduzir beam_width ou aumentar block_small"

# Problema: Qualidade ruim
solution = "Aumentar k_candidates ou local_iters"

# Problema: Timeout frequente
solution = "Reduzir max_time ou simplificar par√¢metros"

# Problema: Uso excessivo de mem√≥ria
solution = "Reduzir k_candidates ou beam_width"
```

## üîó Integra√ß√£o com CSPBench

### Registro Autom√°tico
```python
@register_algorithm
class H2CSPAlgorithm(CSPAlgorithm):
    name = "H¬≤-CSP"
    supports_internal_parallel = False
    is_deterministic = True
```

### Configura√ß√£o via YAML
```yaml
algorithm:
  name: "H¬≤-CSP"
  params:
    beam_width: 32
    k_candidates: 5
    local_iters: 3
    block_small: 2
    block_medium: 4
    max_time: 300
```

### Execu√ß√£o via CLI
```bash
python main.py --algorithm "H¬≤-CSP" --dataset synthetic
python main.py --algorithm "H¬≤-CSP" --dataset file \
  --beam_width 64 --k_candidates 8 --local_iters 5
```

### Suporte a Paraleliza√ß√£o
- **Paralelismo Interno**: ‚ùå N√£o suportado (algoritmo sequencial)
- **Paralelismo de Runs**: ‚úÖ M√∫ltiplas execu√ß√µes independentes
- **Compatibilidade**: ‚úÖ Funciona perfeitamente com batch processing

### Metadados Detalhados
```python
metadata = {
    "iteracoes": 1,
    "algoritmo": "H¬≤-CSP",
    "parametros_usados": {
        "beam_width": 32,
        "k_candidates": 5,
        "local_iters": 3,
        "block_small": 2,
        "block_medium": 4,
        "auto_blocks": True,
        "max_time": 300
    },
    "centro_encontrado": "ACGTACGT"
}
```

### Advanced Usage: Custom Block Strategy
```python
# Implementa√ß√£o customizada (futuro)
class CustomH2CSP(H2CSPAlgorithm):
    def __init__(self, strings, alphabet, **params):
        # Override block division strategy
        params["auto_blocks"] = False
        params["custom_blocks"] = self.define_custom_blocks(strings)
        super().__init__(strings, alphabet, **params)
    
    def define_custom_blocks(self, strings):
        # Custom logic for domain-specific block division
        pass
```

### Integration with Optimization
```python
# H¬≤-CSP funciona perfeitamente com otimiza√ß√£o Optuna
study = optuna.create_study()
study.optimize(
    lambda trial: optimize_h2_csp_params(trial, dataset),
    n_trials=100
)
```

---

**Desenvolvido para CSPBench** - Framework de Experimenta√ß√£o para o Closest String Problem  
üìö Para mais informa√ß√µes, consulte a [documenta√ß√£o principal](../../README.md) do framework.
### Integration with Optimization
```python
# H¬≥-CSP funciona perfeitamente com otimiza√ß√£o Optuna
study = optuna.create_study()
study.optimize(
    lambda trial: optimize_h3_csp_params(trial, dataset),
    n_trials=100
)
```

---

**Desenvolvido para CSPBench** - Framework de Experimenta√ß√£o para o Closest String Problem  
üìö Para mais informa√ß√µes, consulte a [documenta√ß√£o principal](../../README.md) do framework.
