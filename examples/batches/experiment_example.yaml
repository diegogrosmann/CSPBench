# ===================================================================
# STANDARDIZED TEMPLATE CSPBench - UNIFIED STRUCTURE v0.8
# ===================================================================
# This template defines the standard structure for all batch types.
# Infrastructure settings (paths, directories) are configured in .env
# This template only contains execution-specific configurations
# 
# Supported types: execution, optimization, sensitivity
# Usage: Copy this template and adapt for your specific needs
#
# =====================================================================
# SECTION 1: METADATA (REQUIRED FOR ALL)
# =====================================================================
# This section contains basic information about the batch.
# All fields are required for traceability and documentation.
metadata:
  name: "Experiment Example"                  # Descriptive batch name (string)
  description: "Detailed description of what the batch does"
    # Complete description (string)    
  author: "Author Name"               # Responsible author (string)
  version: "1.0"                      # Batch version (string)
  creation_date: "2025-07-13"         # Creation date in YYYY-MM-DD format
  tags: ["tag1", "tag2"]              # Tags for categorization (list)

# =====================================================================
# SECTION 2: DATASETS (STANDARDIZED FOR ALL)
# =====================================================================
# Defines the datasets available for use in the batch.
# Each dataset has a unique ID that can be referenced in executions.
# Supported types: synthetic, file, entrez
datasets:
  # === SYNTHETIC DATASETS ===
  # Generate artificial data for testing and development
  - id: "synthetic_small_dataset"                  # string: Unique dataset ID
    name: "Small"              # string: Descriptive name
    type: "synthetic"                 # string: Dataset type
    parameters:                       # Parameters specific to synthetic datasets:
      # Modo de geração: "random" | "noise" | "mutations" | "clustered"
      mode: "random"

      # Parâmetros comuns
      n: 8
      L: 10
      alphabet: "ACGT"
      seed: null

  - id: "synthetic_medium_dataset"                  # string: Unique dataset ID
    name: "Medio"              # string: Descriptive name
    type: "synthetic"                 # string: Dataset type
    parameters:                       # Parameters specific to synthetic datasets:
      # Modo de geração: "random" | "noise" | "mutations" | "clustered"
      mode: "random"

      # Parâmetros comuns
      n: 40
      L: 80
      alphabet: "ACGT"
      seed: null

# =====================================================================
# SECTION 3: ALGORITHMS (STANDARDIZED FOR ALL)
# =====================================================================
# Defines algorithm configurations that can be reused.
# Allows creating parameter "presets" for different scenarios.
algorithms:
  - id: "full_config"              # string: Unique configuration ID
    name: "Full Configuration"     # string: Descriptive name
    description: "Algorithms with full parameters"           # string: Detailed description
    algorithms:                       # list: List of algorithms included in this configuration
      - "Baseline"                    # Baseline algorithm (simplest)
      - "BLF-GA"                      # Block-based Genetic Algorithm (main)
      - "CSC"                         # Closest String with Constraints
      - "H2-CSP"                       # Heuristic Closest String Problem
      - "DP-CSP"                      # Dynamic Programming CSP
    algorithm_params:                 # dict: Algorithm parameters (optional - empty dict {} if not needed)
      # Algorithms without parameters listed here will use empty parameters automatically
      # Example with parameters:
      # "BLF-GA":
      #   population_size: 100
      #   generations: 50
                                      
  - id: "small_config"              # string: Unique configuration ID
    name: "Small Configuration"                            # string: Descriptive name
    description: "Small Configuration"      # string: Detailed description
    algorithms:                       # list: List of algorithms included in this configuration
      - "CSC"                         # Closest String with Constraints
      - "H2-CSP"                       # Heuristic Closest String Problem
    algorithm_params: {}              # dict: Empty parameters - algorithms will use default/empty parameters
    
# =====================================================================
# SECTION 4: TASK TYPE (REQUIRED)
# =====================================================================
# Defines the type of operation to be performed.
# Each type has specific configurations in the corresponding section.
task:
  type: "experiment"                  # string: Task type
                                      # "experiment" = run algorithms with fixed parameters
                                      # "optimization" = optimize hyperparameters with Optuna
                                      # "sensitivity" = analyze sensitivity with SALib

# =====================================================================
# SECTION 5A: SPECIFIC CONFIGURATION - EXPERIMENT
# =====================================================================
# Use this section when task.type = "experiment"
# Runs algorithms on datasets with pre-defined parameters
experiment:
  tasks:
    # List of experiment tasks to perform (formerly 'executions')
    - name: "Test Experiment"         # string: Descriptive experiment name
      datasets:
        - "synthetic_small_dataset"
#        - "synthetic_medium_dataset"
      algorithms:
#        - "full_config"
        - "small_config"
      repetitions: 5                 # int: Number of repetitions per combination (1-10 recommended)
                                      # Each dataset+algorithm combination will be executed N times

# =====================================================================
# SECTION 7: RESOURCE SETTINGS (OPTIONAL)
# =====================================================================
# Control of computational resource usage
resources:
  # CPU limitations
  cpu:
    # Do not use the same cores as the main application during tests
    exclusive_cores: false            # bool: If true, tests do not share cores with the main app
    max_workers: null                 # int|null: Maximum number of cores to use (null = all available)
    internal_jobs: 4                  # int: Maximum internal parallel jobs per algorithm
                                      # Controls internal algorithm parallelism (threads/processes)
                                      # Suggested value: 4 for CPUs with 8+ cores
                                      # Relation: max_workers × internal_jobs ≤ CPU_cores
  # Timeouts and limits
  timeouts:
    timeout_per_item: 300       # int: Timeout per individual algorithm execution (seconds)
                                      # Applied to each algorithm run independently
                                      # Common values: 1800 (30min), 3600 (1h), 7200 (2h)
    timeout_total_batch: 21600        # int: Total timeout for entire batch execution (seconds)
                                      # Applied to the complete batch process
                                      # Common values: 21600 (6h), 43200 (12h), 86400 (24h)
    
# =====================================================================
# SECTION 8: SYSTEM SETTINGS (OPTIONAL)
# =====================================================================
# General system configurations and behavior
system:
  # Global seed substitution - overrides all local seeds
  global_seed: null                   # int|null: Global seed that replaces all algorithm and dataset seeds
                                      # When set, substitutes ALL seed parameters throughout configuration
                                      # null = use individual seeds, int = override all with this value
  
  seed_increment: true                # bool: Whether to increment seeds for each repetition
                                      # When true, each repetition uses incremented seeds:
                                      # - If global_seed is set: repetition_1: global_seed+1, repetition_2: global_seed+2, etc.
                                      # - If global_seed is null: increments individual algorithm seeds
                                      # This ensures different seeds while maintaining reproducibility
                                      # false = all repetitions use the same seeds
  
  # Distance calculation method
  distance_method: "hamming"          # string: Method for distance calculation
                                      # "hamming" = Hamming distance (current implementation)
                                      # Future: "levenshtein", "edit", "custom"
  
  # Distance calculation cache
  enable_distance_cache: true         # bool: Enable caching for distance calculations
                                      # true = cache results for better performance
                                      # false = calculate distances every time (uses less memory)