"""
NCBI Dataset Download Module - CSPBench

Provides functionality for automatic download of biological sequences
from NCBI via Entrez API for Closest String Problem (CSP) applications.

Configuration:
    Create a .env file in the project root with:
    NCBI_EMAIL=your_email@example.com
    NCBI_API_KEY=your_api_key  # Optional

Author: CSPBench Development Team
"""

import logging
import os
import random
from typing import Any, Dict, List, Tuple
from urllib.error import HTTPError

from dotenv import load_dotenv

load_dotenv()

# TODO: Reimplementar após migração completa
# from cspbench.ui.cli.entrez_wizard import collect_entrez_parameters

try:
    from Bio import Entrez, SeqIO
except ImportError as exc:
    raise ImportError(
        "Biopython not found. Install with: pip install biopython"
    ) from exc

logger = logging.getLogger(__name__)

# Default settings loaded from .env
ENTREZ_DEFAULTS = {
    "email": os.getenv("NCBI_EMAIL", "change_me@example.com"),
    "api_key": os.getenv("NCBI_API_KEY"),
    "db": "nucleotide",
    "n": 20,
    "rettype": "fasta",
    "retmode": "text",
}


def fetch_dataset() -> Tuple[List[str], Dict[str, Any]]:
    """
    Download a dataset from NCBI using default configuration.

    For programmatic use, prefer fetch_dataset_silent().
    """
    # TODO: Reimplement interactive interface
    return fetch_dataset_silent(ENTREZ_DEFAULTS)


def fetch_dataset_silent(params: Dict[str, Any]) -> Tuple[List[str], Dict[str, Any]]:
    """
    Download a dataset from NCBI using provided parameters.

    Args:
        params: Configuration parameters (email, db, term, n, api_key)

    Returns:
        Tuple with list of sequences and used parameters

    Raises:
        ValueError: If error in search, download or validation
        HTTPError: If communication problem with NCBI
    """
    # Mesclar parâmetros com configurações padrão
    merged_params = {**ENTREZ_DEFAULTS}
    merged_params.update(params)

    # Extrair parâmetros de configuração
    email = merged_params["email"]
    db = merged_params["db"]
    term = merged_params["term"]
    n = merged_params["n"]
    api_key = merged_params.get("api_key")

    logger.debug("fetch_dataset_silent chamado com db=%s, term='%s', n=%s", db, term, n)

    # Configurar cliente Entrez
    Entrez.email = email
    if api_key:
        Entrez.api_key = api_key

    # Configurar gerador para seleção reprodutível
    rng = random.Random(0)

    # Fase 1: Buscar IDs das sequências
    logger.debug("Iniciando ESearch...")
    try:
        handle = Entrez.esearch(db=db, term=term, retmax=n * 2)
        search_result = Entrez.read(handle)
        handle.close()
    except HTTPError as e:
        raise ValueError(f"Erro ao acessar NCBI: HTTP {e.code} - {e.reason}") from e
    except Exception as e:
        raise ValueError(f"Erro na busca no NCBI: {e}") from e

    # Validar resultado da busca
    if not isinstance(search_result, dict):
        raise TypeError(
            f"Resultado da busca Entrez não é um dicionário: {type(search_result)}"
        )

    logger.debug("ESearch retornou %s IDs", len(search_result.get("IdList", [])))

    # Extrair IDs dos resultados
    ids = search_result.get("IdList", [])
    if not ids:
        raise ValueError("Nenhum resultado encontrado. Verifique seu termo de busca.")

    # Selecionar IDs para download
    if len(ids) < n:
        logger.warning(
            "A busca retornou %s IDs, menos que os %s solicitados. "
            "Usando todos os IDs encontrados.",
            len(ids),
            n,
        )
        n = len(ids)
        sample_ids = ids
    else:
        # Para compatibilidade com testes VCR, usar primeiros IDs quando n é pequeno
        if n <= 10:
            sample_ids = ids[:n]
        else:
            sample_ids = rng.sample(ids, n)

    logger.debug("IDs amostrados (primeiros 5): %s ...", sample_ids[:5])

    # Fase 2: Download das sequências
    logger.debug("Iniciando EFetch...")
    try:
        fetch_handle = Entrez.efetch(
            db=db, id=",".join(sample_ids), rettype="fasta", retmode="text"
        )
        records = list(SeqIO.parse(fetch_handle, "fasta"))
        fetch_handle.close()
    except HTTPError as e:
        raise ValueError(
            f"Erro ao baixar sequências do NCBI: HTTP {e.code} - {e.reason}"
        ) from e
    except Exception as e:
        raise ValueError(f"Erro no processamento das sequências: {e}") from e

    logger.debug("%s sequências baixadas", len(records))

    # Processar e normalizar sequências
    seqs = [str(rec.seq).upper() for rec in records]

    if not seqs:
        raise ValueError("Nenhuma sequência válida foi obtida")

    # Fase 3: Filtragem por comprimento uniforme
    lengths = [len(seq) for seq in seqs]
    unique_lengths = set(lengths)

    if len(unique_lengths) > 1:
        # Aplicar estratégia de filtragem baseada no tipo de dados
        is_protein = db == "protein"
        is_rna_query = "ribosomal RNA" in term or "rRNA" in term

        if is_protein and not is_rna_query:
            # Proteínas: ser mais permissivo com comprimentos variados
            logger.warning(
                "Sequências de proteínas com comprimentos diferentes encontradas: %s. "
                "Mantendo todas as sequências para análise (dataset proteico).",
                sorted(unique_lengths),
            )
        else:
            # DNA/RNA: aplicar filtragem mais rigorosa
            length_counts = {}
            for length in lengths:
                length_counts[length] = length_counts.get(length, 0) + 1

            # Selecionar o comprimento mais comum
            most_common_length = max(
                length_counts.keys(), key=lambda x: length_counts[x]
            )
            uniform_seqs = [seq for seq in seqs if len(seq) == most_common_length]

            logger.warning(
                "Sequências com comprimentos diferentes encontradas: %s. "
                "Usando apenas sequências de comprimento %s (%s/%s)",
                sorted(unique_lengths),
                most_common_length,
                len(uniform_seqs),
                len(seqs),
            )

            # Verificar se há sequências suficientes
            if len(uniform_seqs) < 2:
                raise ValueError(
                    "Muito poucas sequências de comprimento uniforme encontradas"
                )

            seqs = uniform_seqs

    # Preparar parâmetros de retorno
    used_params = {
        "email": email,
        "db": db,
        "term": term,
        "n": n,
        "api_key": api_key,
        "n_obtained": len(seqs),
    }

    logger.info("Dataset Entrez obtido: n=%s, L=%s", len(seqs), len(seqs[0]))
    return seqs, used_params
